{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PythonのAutoFeatを使った自動特徴量エンジニアリング （Automatic Feature Engineering）その3（特徴量選択だけ使う）\n",
        "\n",
        "url: https://www.salesanalytics.co.jp/datascience/datascience029/\n",
        "\n",
        "    第232話｜3タイプの特徴量エンジニアリング（feature engineering）基礎テクニック\n",
        "\n",
        "url: https://www.salesanalytics.co.jp/column/no00232/#Wrapper_Method"
      ],
      "metadata": {
        "id": "clMZgTjXZ0Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Pythonに幾つかの自動特徴量エンジニアリング（Automatic Feature Engineering）のためのパッケージがあります。\n",
        "\n",
        "    その中の1つに「AutoFeat」というものがあります。回帰問題と分類問題で利用できます。\n",
        "\n",
        "    AutoFeatは非常に簡単に使えます。\n",
        "    ただ、完全な特徴量エンジニアリング（Feature Engineering）を実施してくれるわけではありません。\n",
        "    例えば、欠測値補完や異常値処理、正規化処理などは実施しません。\n",
        "\n",
        "    何をやるかと言うと……\n",
        "\n",
        "    元の特徴量からたくさんの非線形の特徴量を生成し「特徴量プール」を作ります\n",
        "    「特徴量プール」から有効な特徴量を選択します（特徴量選択）\n",
        "    ……という感じです。\n",
        "\n",
        "    前々回は分類問題で、前回は回帰問題でした。\n",
        "\n",
        "    特徴量選択の機能だけ使いたい、という方もいるかもしれません。ということで今回は、特徴量選択の機能だけ使う場合のやり方について、簡単に説明します。"
      ],
      "metadata": {
        "id": "UL95DLZjabDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    【ちょっと理論的なお話し】AutoFeatの特徴量選択方法\n",
        "    先ず、AutoFeatの特徴量選択方法について、簡単な解説をします。興味のない方は、飛ばしてください。\n",
        "\n",
        "    先ほどの説明の繰り返しになりますが、ざっくり説明するとAutoFeatの特徴量エンジニアリング（Feature Engineering）は、次のようになっています。\n",
        "\n",
        "    1.元の特徴量からたくさんの非線形の特徴量を生成し「特徴量プール」を作ります\n",
        "    2.「特徴量プール」から有効な特徴量を選択します（特徴量選択）\n",
        "\n",
        "    「特徴量プール」とは、元の特徴量と新たに生成した非線形の特徴量を合わせた特徴量の集合のことです。この「特徴量プール」に対し、特徴量選択を実施していきます。\n",
        "\n",
        "    特徴量選択は、ざっくり次の2つのステップからなります。\n",
        "\n",
        "    ・先ず、相関の高い特徴量を削る\n",
        "    ・次に、L1正則化で特徴量を選択する\n",
        "\n",
        "    相関の高い特徴量を削るとき、より単純な特徴量（元の特徴量に近い方）を残します。\n",
        "\n",
        "    例えば、xとzという元の特徴量からx^2とz^2という特徴量を作ったとします。xとz^2の相関が高いときxの方を残しz^2の方を削ります。\n",
        "\n",
        "    L1正則化で特徴量で選択するとき、Lasso LARS回帰モデルとL1正則化ロジスティック回帰モデルを活用したラッパー法（Wrapper Method）を使い、特徴量選択をしています。\n",
        "\n",
        "    ・回帰問題に対しLasso LARS回帰モデル\n",
        "    ・分類問題に対しL1正則化ロジスティック回帰モデル\n",
        "\n",
        "    L1正則化で特徴量を選択するとき、「特徴量プール」から「初期セット」を選びます。\n",
        "    そして、「特徴量プール」に残ったものを幾つかに分割し「特徴量のチャンク（塊）」を作ります。\n",
        "    「初期セット」に各チャンクを追加し特徴量セットを作りモデルをフィットさせ、特徴量選択の検討を実施していきます。\n",
        "    そういう意味でラッパー法（Wrapper Method）です。\n",
        "\n",
        "    ラッパー法（Wrapper Method）に関しては以下の記事で簡単に解説していますので、参考にして頂ければと思います。\n",
        "\n",
        "    第232話｜3タイプの特徴量エンジニアリング（feature engineering）基礎テクニック\n",
        "    https://www.salesanalytics.co.jp/column/no00232/#Wrapper_Method\n",
        "\n",
        "    ちなみに、「初期セット」は、すべての特徴量を使いL1正則化線形モデルを学習し、係数の絶対値の大きな特徴量を選んだものです。\n",
        "\n",
        "    ロバスト性（頑健性）を高めるために、データのサンプリングなどを何度も何度も実施し、このようなことを何度も何度も繰り返し検討し、\n",
        "    比較的いつも残る（選択される）特徴量を、最終的な特徴量として選択します。\n",
        "\n",
        "    なぜでこのような面倒なことをするのか？　という疑問もあることでしょう。\n",
        "\n",
        "    最初に実施する、「すべての特徴量を使いL1正則化線形モデルを学習し、係数の絶対値の大きな特徴量を選ぶ」、それだけでいいのではないか？　と思うかもしれません。\n",
        "\n",
        "    しかし、それでは上手くいかないことが知られています。\n",
        "\n",
        "    「すべての特徴量を使いL1正則化線形モデルを学習し、係数の絶対値の大きな特徴量を選ぶ」だけで上手くいく条件があります。それは、特徴量同士の相関が低い場合です。\n",
        "\n",
        "    今回の場合ですと、元の特徴量から非線形な変換をして作っていることもあり、特徴量同士の相関が低いとは言い切れず、\n",
        "    どちらかというと相関の高い特徴量の組み合わせが混じっている可能性が高いです。\n",
        "    今回の例に限らず、どちらかというと相関の高い特徴量の組み合わせが混じっている可能性が高いため、\n",
        "    「すべての特徴量を使いL1正則化線形モデルを学習し、係数の絶対値の大きな特徴量を選ぶ」という方法は多くの場合あまり適切とは言えません。\n",
        "\n",
        "    気になる方は、以下を参考にして頂ければと思います。\n",
        "\n",
        "    Agnostic feature selection\n",
        "    https://hal.archives-ouvertes.fr/hal-02436824\n",
        "\n",
        "    そのため、AutoFeatではこのようなアプローチで特徴量選択を実施しています。"
      ],
      "metadata": {
        "id": "8KyYoZfUaefK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoFeatのFeature Selectorを使って見よう！\n",
        "    今回は、意図的に特徴量（説明変数）を膨大にするために、Scikit-Learn（sklearn）を使い以下のようなサンプルデータセットを生成し、特徴量選択を実施しています。\n",
        "\n",
        "    回帰問題用に生成するサンプルデータ\n",
        "    ・サンプル数：1,100\n",
        "    ・特徴量の数：1,000\n",
        "\n",
        "    分類問題用に生成するサンプルデータ\n",
        "    ・サンプル数：1,100\n",
        "    ・特徴量の数：1,000\n",
        "    ・目的変数のクラス数：2"
      ],
      "metadata": {
        "id": "_wC2jX_BamMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ライブラリーの読み込み\n",
        "    先ず、必要なライブラリーを読み込みます。"
      ],
      "metadata": {
        "id": "qFIbXDc_ne1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autofeat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbOub3QxoK-g",
        "outputId": "3cc148f1-bde4-4dcb-c025-52db3fa87904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autofeat\n",
            "  Downloading autofeat-2.1.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autofeat) (1.3.2)\n",
            "Requirement already satisfied: numba>=0.53.1 in /usr/local/lib/python3.10/dist-packages (from autofeat) (0.58.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from autofeat) (1.23.5)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from autofeat) (1.5.3)\n",
            "Collecting pint<1.0,>=0.17 (from autofeat)\n",
            "  Downloading Pint-0.23-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.0/305.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autofeat) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from autofeat) (1.11.4)\n",
            "Requirement already satisfied: sympy<2.0.0,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from autofeat) (1.12)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53.1->autofeat) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.3.5->autofeat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.3.5->autofeat) (2023.3.post1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pint<1.0,>=0.17->autofeat) (4.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.0->autofeat) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy<2.0.0,>=1.7.1->autofeat) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3.0.0,>=1.3.5->autofeat) (1.16.0)\n",
            "Installing collected packages: pint, autofeat\n",
            "Successfully installed autofeat-2.1.2 pint-0.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリーの読み込み\n",
        "import pandas as pd\n",
        "from autofeat import FeatureSelector\n",
        "from sklearn.datasets import make_regression, make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
        "from sklearn.metrics import r2_score,accuracy_score"
      ],
      "metadata": {
        "id": "eURohMDEoGGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 回帰問題に対する特徴量選択例\n",
        "    次に、サンプルデータセットを生成します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "bX2QOM2hf82c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# サンプルデータの生成\n",
        "X, y = make_regression(n_samples=1100,   #サンプルの数\n",
        "                       n_features=1000,  #特徴量の数\n",
        "                       n_informative=10, #目的変数と関連性の強い特徴量の数\n",
        "                       noise=10,         #ノイズの標準偏差\n",
        "                       bias=0,           #バイアス（切片）\n",
        "                       random_state=12)\n",
        "\n",
        "X = pd.DataFrame(X)\n",
        "y = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "_4q4IGeYrHxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(X)\n",
        "display(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "jtRWADg9oTrh",
        "outputId": "3ea06635-414e-4050-f10e-b35a18652da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74af06cf-bbb1-49d8-b6ff-8b7dc8f3d256\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74af06cf-bbb1-49d8-b6ff-8b7dc8f3d256')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74af06cf-bbb1-49d8-b6ff-8b7dc8f3d256 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74af06cf-bbb1-49d8-b6ff-8b7dc8f3d256');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c08a3b6a-db80-4e3f-aed2-10cc96f32934\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c08a3b6a-db80-4e3f-aed2-10cc96f32934')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c08a3b6a-db80-4e3f-aed2-10cc96f32934 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7d7dd481-a3d3-4edb-aad0-5dbdff8b9d48\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7d7dd481-a3d3-4edb-aad0-5dbdff8b9d48 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "564    0\n",
              "565    0\n",
              "566    0\n",
              "567    0\n",
              "568    1\n",
              "Name: target, Length: 569, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    生成したデータセットを学習データとテストデータに分割します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "wJ7_a3q4ln45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットの分割（学習データとテストデータ）\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    train_size=0.5,\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "YHbNPo-XmHoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    学習データ\n",
        "    特徴量：X_train\n",
        "    目的変数：y_train\n",
        "    \n",
        "    テストデータ\n",
        "    特徴量：X_test\n",
        "    目的変数：y_test"
      ],
      "metadata": {
        "id": "pAHecXgFloBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    変数選択用のモデルを定義します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "pDPzrTlJiCJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル定義\n",
        "model = FeatureSelector(problem_type=\"regression\",verbose=1)"
      ],
      "metadata": {
        "id": "jefEtWlJiBiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    学習データを利用し特徴量選択を実施します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "9yhxE-GGiIRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量選択（学習データ利用）\n",
        "X_train_fsel = model.fit_transform(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "SAmPqqHliBjz",
        "outputId": "f25ad1c9-9a7b-4d82-a7e0-7bcdb6b50179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:236: RuntimeWarning: overflow encountered in multiply\n",
            "  x = um.multiply(x, x, out=x)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:247: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e1c7ab728f11>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 特徴量生成（学習データ利用）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_feature_creation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autofeat/autofeat.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mgood_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_subs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             good_cols = select_features(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mdf_subs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mtarget_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autofeat/featsel.py\u001b[0m in \u001b[0;36mselect_features\u001b[0;34m(df, target, featsel_runs, keep, problem_type, n_jobs, verbose)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mselected_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatsel_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mselected_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_select_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autofeat/featsel.py\u001b[0m in \u001b[0;36mrun_select_features\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mrand_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.85\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_select_features_1run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeatsel_runs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mproblem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autofeat/featsel.py\u001b[0m in \u001b[0;36m_select_features_1run\u001b[0;34m(df, target, problem_type, verbose)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# TODO: remove if sklearn least_angle issue is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# try once more with shuffled data, if it still doesn't work, give up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1867\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"processes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1869\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1870\u001b[0m             path_func(\n\u001b[1;32m   1871\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     coefs, Cs, n_iter = _logistic_regression_path(\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             w0, n_iter_i, warm_start_sag = sag_solver(\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0msag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msag64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msag32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     num_seen, n_iter_ = sag(\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    元の特徴量からどのくらい減ったのかを見てみます。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "aicT75LCooXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of features in X_train:\",\n",
        "      X_train.shape[1])                  #元の特徴量Xの数\n",
        "print(\"number of features in X_train_fsel:\",\n",
        "      X_train_fsel.shape[1])             #選択された特徴量Xの数\n",
        "\n",
        "# 1,000個あった特徴量が、23個に減っています。"
      ],
      "metadata": {
        "id": "7M6RpeiCo_zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    これで、モデルの予測精度が恐ろしく悪化したのでは、身も蓋もありません。\n",
        "\n",
        "    テストデータで確認してみます。"
      ],
      "metadata": {
        "id": "GbHDQTbmieFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    この自動選択した特徴量と同じ特徴量のテストデータを作ります。X_test_fselに格納します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "z0aLJGmSs-rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータの特徴量生成\n",
        "X_test_fsel = model.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pdc9jE8iBnr",
        "outputId": "71355fa5-c0f1-4c6a-9793-3639e92fe6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
              "       'Latitude', 'Longitude', 'MedInc**5', 'HouseAge/AveOccup',\n",
              "       'log(MedInc)/AveOccup', 'Longitude**3/Latitude',\n",
              "       'HouseAge**3*Population', 'AveBedrms**2*MedInc**3',\n",
              "       'MedInc**2*log(AveOccup)', '1/(HouseAge*Population)',\n",
              "       'log(Population)/AveBedrms', 'sqrt(Population)/AveOccup',\n",
              "       'sqrt(HouseAge)*Latitude**3', 'sqrt(HouseAge)*log(AveRooms)',\n",
              "       'Population/MedInc', 'AveRooms/AveBedrms', 'HouseAge*MedInc**3',\n",
              "       '1/(AveOccup*MedInc)', 'AveOccup/Population', 'sqrt(HouseAge)*MedInc',\n",
              "       'log(AveBedrms)/MedInc', '1/(AveBedrms*AveOccup)',\n",
              "       'HouseAge**2/Population', '1/(AveBedrms*Latitude)',\n",
              "       'Population**2/AveOccup', 'log(AveRooms)/AveRooms',\n",
              "       'Latitude**3*log(MedInc)', 'HouseAge*log(AveBedrms)',\n",
              "       'MedInc*sqrt(Population)', 'AveRooms*sqrt(Population)',\n",
              "       'log(AveOccup)*log(MedInc)', 'sqrt(Population)/HouseAge',\n",
              "       'sqrt(AveRooms)*Latitude**3', 'AveOccup/HouseAge', 'MedInc**3/HouseAge',\n",
              "       'log(MedInc)/MedInc', '1/(HouseAge*MedInc)', 'log(AveOccup)/AveBedrms',\n",
              "       'log(Population)/AveRooms', 'log(AveBedrms)/Population',\n",
              "       'Latitude**2*log(AveOccup)', 'AveOccup**2*log(AveBedrms)',\n",
              "       'sqrt(Population)*log(AveBedrms)', '1/Population', 'AveRooms/MedInc',\n",
              "       'AveRooms*MedInc', 'HouseAge**2/MedInc', '1/(AveRooms*MedInc)',\n",
              "       'log(AveOccup)/MedInc', 'log(MedInc)/Population',\n",
              "       'AveBedrms**2*Population'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    元の特徴量のデータセット（X_trainとy_train）と新たな特徴量のデータセット（X_train_fselとy_train）で、線形回帰（重回帰）モデルを構築してみます。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "_KdZNC2KikMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of features in X_train:\",  #元の特徴量Xの数\n",
        "      X_train.shape[1])\n",
        "print(\"number of features in X_train_feature_creation:\",\n",
        "      X_train_feature_creation.shape[1]) #新しい特徴量Xの数\n",
        "\n",
        "# 元の特徴量は30個でしたが、AutoFeatによる特徴量の自動生成で9個の特徴量が新たに追加され、結果的に39個の特徴量になりました。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMsDBiV3iBpx",
        "outputId": "f15dbeaf-0bbd-43ac-a16c-b265b8bb6514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of features in X_train: 8\n",
            "number of features in X_train_feature_creation: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    この自動生成した特徴量と同じ特徴量のテストデータを作ります。X_test_feature_creationに格納します。"
      ],
      "metadata": {
        "id": "fIvM-M4ziv9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル構築\n",
        "model_1 = LinearRegression().fit(X_train,y_train)\n",
        "model_2 = LinearRegression().fit(X_train_fsel, y_train)"
      ],
      "metadata": {
        "id": "rhElghx3iBtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    モデルの精度（R2：決定係数）を比較してみたいと思います。学習データとテストデータでそれぞれで比較してみます。\n",
        "\n",
        "    先ず、学習データでモデルの精度（R2：決定係数）を比較します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "qGHnFwfTjzMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価（R2）　※学習データ\n",
        "print(\"model_1   R^2: %.4f\" % r2_score(y_train, model_1.predict(X_train)) )\n",
        "print(\"model_2   R^2: %.4f\" % r2_score(y_train, model_2.predict(X_train_fsel)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI3kuNKkiBvg",
        "outputId": "9f1b59fe-c6d2-4c7f-84c1-6d7563f53bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_1   R^2: 0.5958\n",
            "model_2   R^2: 0.6868\n",
            "LassoLars R^2: 0.6686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    学習データを使った精度検証なので、基本高精度になります。\n",
        "\n",
        "    元の特徴量のデータセットを使った方の決定係数は100%と高精度です。一方、特徴量を絞った新たな特徴量のデータセットを使った方の決定係数は99.71%と精度が若干落ちます。\n",
        "\n",
        "    特徴量の数が減ったので当然の結果ですが、大幅に特徴量を減らした割に、それほど精度悪化していないことが分かります。"
      ],
      "metadata": {
        "id": "ZL3SNV4dj_ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    次に、テストデータでモデルの精度（R2：決定係数）を比較します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "eKRwhna-kD2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価（R2）　※テストデータ\n",
        "print(\"model_1   R^2: %.4f\" % r2_score(y_test, model_1.predict(X_test)) )\n",
        "print(\"model_2   R^2: %.4f\" % r2_score(y_test, model_2.predict(X_test_fsel)))\n",
        "\n",
        "# テストデータを使った精度検証なので、学習データに対する決定係数よりも基本悪化します。問題は、どの程度悪化するのか、ということになります"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq6xra9YkUXU",
        "outputId": "7bbc34c1-5787-45ad-c566-8c3c996bdca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tpot\n",
            "  Downloading TPOT-0.12.1-py3-none-any.whl (87 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.2.2)\n",
            "Collecting deap>=1.2 (from tpot)\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting update-checker>=0.16 (from tpot)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from tpot) (4.66.1)\n",
            "Collecting stopit>=1.1.1 (from tpot)\n",
            "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.5.3)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from tpot) (1.3.2)\n",
            "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tpot) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->tpot) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->tpot) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update-checker>=0.16->tpot) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->tpot) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2023.11.17)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11937 sha256=5b603467bdf12209067355a41e9127ca9d813959ff47e6d7997131499cd668b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/f9/87/bf5b3d565c2a007b4dae9d8142dccc85a9f164e517062dd519\n",
            "Successfully built stopit\n",
            "Installing collected packages: stopit, deap, update-checker, tpot\n",
            "Successfully installed deap-1.4.1 stopit-1.1.2 tpot-0.12.1 update-checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    元の特徴量のデータセットを使った方の決定係数は49.39%と悪化します。\n",
        "    一方、特徴量を絞った新たな特徴量のデータセットを使った方の決定係数は99.47%と高精度のままです。\n",
        "\n",
        "    特徴量選択が上手くいっていることが分かるかと思います。"
      ],
      "metadata": {
        "id": "2S3qKbUUqPeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分類問題に対する特徴量選択例\n",
        "    先ず、サンプルデータセットを生成します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "cNGxaNpHtgPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# サンプルデータの生成\n",
        "X, y = make_classification(n_samples=1100,   #サンプルの数\n",
        "                           n_features=1000,  #特徴量の数\n",
        "                           n_informative=10, #目的変数と関連性の強い特徴量の数\n",
        "                           n_classes=2,      #目的変数のクラスの数\n",
        "                           random_state=12)\n",
        "\n",
        "X = pd.DataFrame(X)\n",
        "y = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "_ZZU40kXtm-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    生成したデータセットを学習データとテストデータに分割します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "6oQlo9Ests6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットの分割（学習データとテストデータ）\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    train_size=0.5,\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "_feVabh0tnAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    学習データ\n",
        "    特徴量：X_train\n",
        "    目的変数：y_train\n",
        "    \n",
        "    テストデータ\n",
        "    特徴量：X_test\n",
        "    目的変数：y_test"
      ],
      "metadata": {
        "id": "910YLqyZtwc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    変数選択用のモデルを定義します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "MfLFrHJztyp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル定義\n",
        "model = FeatureSelector(problem_type=\"classification\",verbose=1)"
      ],
      "metadata": {
        "id": "WuTNO_j2tnCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    学習データを利用し特徴量選択を実施します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "SgAH3bYnt1Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量選択（学習データ利用）\n",
        "X_train_fsel = model.fit_transform(X_train, y_train)"
      ],
      "metadata": {
        "id": "Wt1cGHbgtnEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    元の特徴量からどのくらい減ったのかを見てみます。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "7eMgawu_t3mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of features in X_train:\",  #元の特徴量Xの数\n",
        "      X_train.shape[1])\n",
        "print(\"number of features in X_train_fsel:\",\n",
        "      X_train_fsel.shape[1])             #選択された特徴量Xの数"
      ],
      "metadata": {
        "id": "SYcwo7QVtnGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    1,000個あった特徴量が、13個に減っています。\n",
        "\n",
        "    これで、モデルの予測精度が恐ろしく悪化したのでは、身も蓋もありません。\n",
        "\n",
        "    テストデータで確認してみます。"
      ],
      "metadata": {
        "id": "b3mDC7I8uEUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    この自動選択した特徴量と同じ特徴量のテストデータを作ります。X_test_fselに格納します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "i86GKsMvuGDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータの特徴量生成\n",
        "X_test_fsel = model.transform(X_test)"
      ],
      "metadata": {
        "id": "cj08EcNotnIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    元の特徴量のデータセット（X_trainとy_train）と新たな特徴量のデータセット（X_train_fselとy_train）で、ロジスティック回帰モデルを構築してみます。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "UxAOO26KuJB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル構築\n",
        "## model_1\n",
        "model_1 = LogisticRegression(class_weight='balanced')\n",
        "model_1.fit(X_train,y_train)\n",
        "\n",
        "## model_2\n",
        "model_2 = LogisticRegression(class_weight='balanced')\n",
        "model_2.fit(X_train_fsel, y_train)"
      ],
      "metadata": {
        "id": "korNwQm-tnLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    モデルの精度（accuracy：正答率）を比較してみたいと思います。\n",
        "    学習データとテストデータでそれぞれで比較してみます。\n",
        "\n",
        "    先ず、学習データでモデルの精度（accuracy：正答率）を比較します。\n",
        "\n",
        "    以下、コードです。\n",
        "\n"
      ],
      "metadata": {
        "id": "tPZGSYO-uNQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価（accuracy）　※学習データ\n",
        "print(\"model_1 accuracy:%.4f\" % accuracy_score(y_train,\n",
        "      model_1.predict(X_train)) )\n",
        "print(\"model_2 accuracy:%.4f\" % accuracy_score(y_train,\n",
        "      model_2.predict(X_train_fsel)))"
      ],
      "metadata": {
        "id": "k3g9FCyhtnMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    学習データを使った精度検証なので、基本高精度になります。\n",
        "\n",
        "    元の特徴量のデータセットを使った方の正答率は100%と高精度です。一方、特徴量を絞った新たな特徴量のデータセットを使った方の正答率は88.55%と精度が若干落ちます。\n",
        "\n",
        "    特徴量の数が減ったので当然の結果ですが、大幅に特徴量を減らした割に、それほど精度悪化していないことが分かります。"
      ],
      "metadata": {
        "id": "yRwzcl3guRda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    次に、テストデータでモデルの精度（accuracy：正答率）を比較します。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "3kgddot2uTL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価（accuracy）　※テストデータ\n",
        "print(\"model_1 accuracy:%.4f\" % accuracy_score(y_test,\n",
        "      model_1.predict(X_test)) )\n",
        "print(\"model_2 accuracy:%.4f\" % accuracy_score(y_test,\n",
        "      model_2.predict(X_test_fsel)))"
      ],
      "metadata": {
        "id": "fPFQXelnuQBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    テストデータを使った精度検証なので、学習データに対する正答率よりも基本悪化します。問題は、どの程度悪化するのか、ということになります。\n",
        "\n",
        "    元の特徴量のデータセットを使った方の正答率は75.64%と悪化します。一方、特徴量を絞った新たな特徴量のデータセットを使った方の正答率は81.64%と高精度のままです。\n",
        "\n",
        "    特徴量選択が上手くいっていることが分かるかと思います。"
      ],
      "metadata": {
        "id": "O-h8QhrMuZ1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## まとめ\n",
        "    人によっては、特徴量選択の機能だけ使いたい、という方もいるかもしれません。今回は、特徴量選択の機能だけ使う場合のやり方について、簡単に説明しました。"
      ],
      "metadata": {
        "id": "ImgkXWKaud8q"
      }
    }
  ]
}