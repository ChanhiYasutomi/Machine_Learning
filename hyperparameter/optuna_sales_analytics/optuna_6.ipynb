{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Optunaで学ぶベイズハイパーパラメータチューニング超入門 – 第6回: OptunaSearchCVを活用したscikit-learnモデルの最適化テクニック –\n",
        "\n",
        "url: https://www.salesanalytics.co.jp/datascience/datascience196/"
      ],
      "metadata": {
        "id": "clMZgTjXZ0Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    ハイパーパラメータチューニングは、機械学習モデルの性能を最大限に引き出す鍵となるステップです。\n",
        "\n",
        "    前回、複数の目的変数を持つマルチオブジェクティブチューニングの基本からParetoフロントの考え方、そして実際のコード例を通してその実装方法を学びました。\n",
        "\n",
        "    url: https://www.salesanalytics.co.jp/datascience/datascience195/"
      ],
      "metadata": {
        "id": "UL95DLZjabDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Optunaはこのプロセスを効率的に行うための強力なツールですが、scikit-learnとの統合はどうすればよいのでしょうか？\n",
        "\n",
        "    今回は「OptunaSearchCVを活用したscikit-learnモデルの最適化テクニック」です。\n",
        "\n",
        "    scikit-learnはPythonの機械学習ライブラリとして非常にポピュラーで、多くのデータサイエンティストや研究者が利用しています。\n",
        "\n",
        "    Optunaとscikit-learnの連携方法として提供されているOptunaSearchCVの活用方法を中心に解説していきます。"
      ],
      "metadata": {
        "id": "8KyYoZfUaefK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OptunaSearchCVとは？\n",
        "### OptunaSearchCVの概要説明\n",
        "    機械学習のモデリングにおいて、最適なハイパーパラメータを見つけるプロセスは非常に重要です。\n",
        "    特にscikit-learnのようなライブラリを用いてモデリングする際、手動でハイパーパラメータを調整するのは時間がかかり、効率が良くありません。ここでOptunaSearchCVの出番です。\n",
        "\n",
        "    OptunaSearchCVは、Optunaのハイパーパラメータ最適化機能をscikit-learnのAPIと統合したものです。\n",
        "\n",
        "    具体的には、scikit-learnのGridSearchCVやRandomizedSearchCVと同様のインターフェースを持ちつつ、背後でOptunaのサンプリングやプルーニングの機能を利用して、ハイパーパラメータの最適化を行います。"
      ],
      "metadata": {
        "id": "_wC2jX_BamMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## scikit-learnとの統合の利点\n",
        "    OptunaSearchCVを使用する最大の利点は、scikit-learnの使い勝手の良さを維持しながら、Optunaの高度なハイパーパラメータ最適化テクニックを利用できる点にあります。\n",
        "\n",
        "    具体的には以下のようなメリットが挙げられます。\n",
        "\n",
        "    ・既存のコードの変更最小化: OptunaSearchCVはscikit-learnのインターフェースと互換性があるため、既存のコードを最小限の変更でOptunaの利点を享受できます。\n",
        "    ・効率的なサンプリング: Optunaのサンプリング技術を背後で利用するため、ハイパーパラメータの探索空間を効率的にサンプルできます。\n",
        "    ・プルーニングの活用: 不必要に悪い結果をもたらすトライアルを早期に打ち切り、計算リソースを節約することができます。"
      ],
      "metadata": {
        "id": "QkXIDSMGfue7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 通常のハイパーパラメータチューニングとの違いは？\n",
        "    OptunaによるハイパーパラメータチューニングとOptunaSearchCVの主な違いは、OptunaSearchCVがscikit-learnのAPIとの統合を強化している点にあります。\n",
        "\n"
      ],
      "metadata": {
        "id": "9VLAFa8ef4_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## インターフェースの統一性\n",
        "    ・通常のOptuna\n",
        "    Optunaの基本的なハイパーパラメータチューニングでは、目的関数を定義し、その中でモデルのトレーニングや評価を行います。\n",
        "    この際、ハイパーパラメータはtrial.suggest_メソッドを用いてサンプリングします。\n",
        "\n",
        "    ・OptunaSearchCV\n",
        "    scikit-learnのGridSearchCVやRandomizedSearchCVと同じインターフェースを持ちます。\n",
        "    このため、パラメータの探索空間を辞書として定義し、Estimator（モデル）とともにOptunaSearchCVに渡します。"
      ],
      "metadata": {
        "id": "eNVjHFfrpdWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## コードの変更の容易さ\n",
        "    ・通常のOptuna\n",
        "    Optunaの目的関数形式に書き換える必要があります。\n",
        "\n",
        "    ・OptunaSearchCV\n",
        "    scikit-learnのAPIとの互換性があるため、既存のGridSearchCVやRandomizedSearchCVを使用しているコードを簡単にOptunaSearchCVに置き換えることができます。"
      ],
      "metadata": {
        "id": "wUphurEkpjpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結果の取得\n",
        "    ・通常のOptuna\n",
        "    スタディオブジェクトから直接最適なトライアルやその他の情報を取得します。\n",
        "\n",
        "    ・OptunaSearchCV\n",
        "    GridSearchCVやRandomizedSearchCVと同様に、最適なハイパーパラメータやモデルのスコアをOptunaSearchCVオブジェクトの属性から取得できます。"
      ],
      "metadata": {
        "id": "n4nvW7fPpo5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用場面\n",
        "    ・通常のOptuna\n",
        "    よりカスタマイズ可能で、非scikit-learnベースのモデルやライブラリ（例: TensorFlow, PyTorch）との統合も簡単です。\n",
        "\n",
        "    ・OptunaSearchCV\n",
        "    scikit-learnのEstimatorと連携する場面での利用が適しています。"
      ],
      "metadata": {
        "id": "BZI8pOkcptf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OptunaSearchCVの基本的な使い方\n",
        "    OptunaSearchCVの使用方法は、scikit-learnのGridSearchCVやRandomizedSearchCVに非常に似ています。\n",
        "\n",
        "    以下は、単純な分類問題にOptunaSearchCVを適用する例です。"
      ],
      "metadata": {
        "id": "79PJVh5SpxIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsYkwLfAn4KQ",
        "outputId": "21090fc6-3453-46e8-a514-f70c02a88bcd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.4)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.1 colorlog-6.8.2 optuna-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from optuna.integration import OptunaSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import optuna\n",
        "\n",
        "# データの準備\n",
        "iris = load_iris() # アヤメ（アイリス）のデータをロード\n",
        "X = iris.data # 説明変数\n",
        "y = iris.target # 目的変数\n",
        "\n",
        "# データをトレーニングセットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "# ハイパーパラメータの探索空間の定義\n",
        "param_distributions = {\n",
        "    'C': optuna.distributions.FloatDistribution(1, 10), # Cの探索範囲を1から10まで\n",
        "    'gamma': optuna.distributions.FloatDistribution(1e-6, 1e-1, log=True) # gammaの探索範囲を10^-6から10^-1まで、対数スケール\n",
        "}\n",
        "\n",
        "clf = SVC() # サポートベクトルマシンの定義\n",
        "optuna_search = OptunaSearchCV(\n",
        "    clf,\n",
        "    param_distributions,\n",
        "    n_trials=100, # トライアル回数\n",
        "    scoring='accuracy', # 評価指標\n",
        "    n_jobs=-1 # 計算するコアの数\n",
        ")\n",
        "\n",
        "optuna_search.fit(X_train, y_train) # モデルの学習\n",
        "y_pred = optuna_search.predict(X_test) # テストデータに対する予測\n",
        "\n",
        "print(\"Best parameters: \", optuna_search.best_params_) # 最良のパラメータの表示\n",
        "print(\"Test set accuracy: \", accuracy_score(y_test, y_pred)) # テストデータに対する予測精度の表示\n",
        "\n",
        "# 以下、実行結果です。ハイパーパラメータの探索結果（Best parameters）と、テストデータの正答率（accuracy）を表示しています。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYUxswpVn3de",
        "outputId": "34f0cfb8-fd79-431e-9f94-04d5ac93f560"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-99f608604bd8>:24: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
            "  optuna_search = OptunaSearchCV(\n",
            "[I 2024-01-28 01:20:40,652] A new study created in memory with name: no-name-67a080bf-4add-4d17-8bc8-715c4b0ca61d\n",
            "[I 2024-01-28 01:20:40,717] Trial 0 finished with value: 0.4391304347826087 and parameters: {'C': 3.4481776084952394, 'gamma': 0.0001427484760453466}. Best is trial 0 with value: 0.4391304347826087.\n",
            "[I 2024-01-28 01:20:40,740] Trial 1 finished with value: 0.7517786561264822 and parameters: {'C': 7.2838962939149035, 'gamma': 0.00033306516397310133}. Best is trial 1 with value: 0.7517786561264822.\n",
            "[I 2024-01-28 01:20:40,774] Trial 2 finished with value: 0.9458498023715414 and parameters: {'C': 1.6636983304270667, 'gamma': 0.0368229636936013}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:40,791] Trial 3 finished with value: 0.9193675889328062 and parameters: {'C': 5.7150287573509075, 'gamma': 0.0015813129051442407}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:40,834] Trial 4 finished with value: 0.9015810276679842 and parameters: {'C': 4.639970745624311, 'gamma': 0.0015323391819892242}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:40,871] Trial 5 finished with value: 0.4391304347826087 and parameters: {'C': 4.769327912974806, 'gamma': 2.4756400754847667e-05}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:40,897] Trial 6 finished with value: 0.9458498023715414 and parameters: {'C': 7.366516274857249, 'gamma': 0.00492152684971422}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:40,947] Trial 7 finished with value: 0.8225296442687748 and parameters: {'C': 2.766825898626643, 'gamma': 0.001251627347743943}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:40,995] Trial 8 finished with value: 0.9189723320158103 and parameters: {'C': 1.4612242303320206, 'gamma': 0.012792916060519957}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:41,012] Trial 9 finished with value: 0.9458498023715414 and parameters: {'C': 2.1039998970153073, 'gamma': 0.02721383259451271}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:41,053] Trial 10 finished with value: 0.4391304347826087 and parameters: {'C': 8.236493406681912, 'gamma': 7.569318137323403e-06}. Best is trial 2 with value: 0.9458498023715414.\n",
            "[I 2024-01-28 01:20:41,127] Trial 11 finished with value: 0.9462450592885375 and parameters: {'C': 9.116113858764098, 'gamma': 0.0686363116943045}. Best is trial 11 with value: 0.9462450592885375.\n",
            "[I 2024-01-28 01:20:41,233] Trial 12 finished with value: 0.9462450592885375 and parameters: {'C': 9.71201107177884, 'gamma': 0.05865535522149753}. Best is trial 11 with value: 0.9462450592885375.\n",
            "[I 2024-01-28 01:20:41,303] Trial 13 finished with value: 0.9462450592885375 and parameters: {'C': 9.942245858095255, 'gamma': 0.07286431937698586}. Best is trial 11 with value: 0.9462450592885375.\n",
            "[I 2024-01-28 01:20:41,377] Trial 14 finished with value: 0.9549407114624506 and parameters: {'C': 9.644403281183415, 'gamma': 0.09716595993814729}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,420] Trial 15 finished with value: 0.9549407114624506 and parameters: {'C': 9.775131674899512, 'gamma': 0.09999010072422793}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,464] Trial 16 finished with value: 0.9458498023715414 and parameters: {'C': 8.558836464217862, 'gamma': 0.006312269982415608}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,510] Trial 17 finished with value: 0.4391304347826087 and parameters: {'C': 8.467054352149162, 'gamma': 1.2661756298812228e-06}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,587] Trial 18 finished with value: 0.4391304347826087 and parameters: {'C': 6.844946069312698, 'gamma': 8.650304841049073e-05}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,637] Trial 19 finished with value: 0.9458498023715414 and parameters: {'C': 7.222902472870739, 'gamma': 0.010247615614072423}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,707] Trial 20 finished with value: 0.9458498023715414 and parameters: {'C': 6.23271228961455, 'gamma': 0.011437448878044596}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,790] Trial 21 finished with value: 0.9276679841897233 and parameters: {'C': 6.131006300383824, 'gamma': 0.0034876928085106874}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,857] Trial 22 finished with value: 0.9371541501976285 and parameters: {'C': 8.908845758362512, 'gamma': 0.096661575839723}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,908] Trial 23 finished with value: 0.9371541501976285 and parameters: {'C': 9.153743970255956, 'gamma': 0.0916411970066398}. Best is trial 14 with value: 0.9549407114624506.\n",
            "[I 2024-01-28 01:20:41,969] Trial 24 finished with value: 0.9727272727272727 and parameters: {'C': 9.416838780443127, 'gamma': 0.027207085506127392}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,059] Trial 25 finished with value: 0.9545454545454547 and parameters: {'C': 9.386236898486098, 'gamma': 0.02395761884759011}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,138] Trial 26 finished with value: 0.9458498023715414 and parameters: {'C': 7.920596364939056, 'gamma': 0.024291858896848928}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,231] Trial 27 finished with value: 0.9458498023715414 and parameters: {'C': 8.397779577395484, 'gamma': 0.019155876844187385}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,311] Trial 28 finished with value: 0.9545454545454547 and parameters: {'C': 9.90750909242239, 'gamma': 0.022961274395617796}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,402] Trial 29 finished with value: 0.9102766798418973 and parameters: {'C': 9.505411812623327, 'gamma': 0.000553175366570948}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,497] Trial 30 finished with value: 0.7517786561264822 and parameters: {'C': 7.870568083763032, 'gamma': 0.0002701797055033688}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,553] Trial 31 finished with value: 0.4391304347826087 and parameters: {'C': 7.863318941640183, 'gamma': 0.0001201129201031075}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,604] Trial 32 finished with value: 0.9636363636363636 and parameters: {'C': 9.176113203756934, 'gamma': 0.041744254310480976}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,654] Trial 33 finished with value: 0.9549407114624506 and parameters: {'C': 9.293743268434378, 'gamma': 0.04332783072570948}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,696] Trial 34 finished with value: 0.9549407114624506 and parameters: {'C': 9.001119642042672, 'gamma': 0.03629942028403585}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,751] Trial 35 finished with value: 0.9636363636363636 and parameters: {'C': 9.988561161897145, 'gamma': 0.04051514360470759}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,847] Trial 36 finished with value: 0.9367588932806324 and parameters: {'C': 9.786858528320941, 'gamma': 0.0027361393007624014}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:42,921] Trial 37 finished with value: 0.9193675889328062 and parameters: {'C': 3.9356742353109055, 'gamma': 0.002388877277783377}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,012] Trial 38 finished with value: 0.9458498023715414 and parameters: {'C': 3.91536895168515, 'gamma': 0.007807604529266591}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,073] Trial 39 finished with value: 0.9458498023715414 and parameters: {'C': 8.878427604166236, 'gamma': 0.006934888815859551}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,154] Trial 40 finished with value: 0.9015810276679842 and parameters: {'C': 8.753474267085569, 'gamma': 0.0009374307773617449}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,197] Trial 41 finished with value: 0.9458498023715414 and parameters: {'C': 7.413870618285303, 'gamma': 0.014566309042709216}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,300] Trial 42 finished with value: 0.9636363636363636 and parameters: {'C': 9.506192060985674, 'gamma': 0.04579965121447493}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,346] Trial 43 finished with value: 0.9636363636363636 and parameters: {'C': 9.980023040767907, 'gamma': 0.04555798116107668}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,416] Trial 44 finished with value: 0.9458498023715414 and parameters: {'C': 5.084091402056677, 'gamma': 0.04270951046574229}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,461] Trial 45 finished with value: 0.9458498023715414 and parameters: {'C': 5.124141723287815, 'gamma': 0.042719970594099356}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,519] Trial 46 finished with value: 0.9549407114624506 and parameters: {'C': 9.351678744643092, 'gamma': 0.043406105846304936}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,555] Trial 47 finished with value: 0.9458498023715414 and parameters: {'C': 9.997023952621069, 'gamma': 0.015960796929727468}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,629] Trial 48 finished with value: 0.9458498023715414 and parameters: {'C': 8.130164911238172, 'gamma': 0.014352511404801148}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,644] Trial 49 finished with value: 0.9458498023715414 and parameters: {'C': 8.095449349090348, 'gamma': 0.004057285897292987}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,724] Trial 50 finished with value: 0.4391304347826087 and parameters: {'C': 8.642115633533184, 'gamma': 2.4433969543236038e-05}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,764] Trial 51 finished with value: 0.4391304347826087 and parameters: {'C': 2.32562156855756, 'gamma': 4.331632308285129e-05}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,819] Trial 52 finished with value: 0.9458498023715414 and parameters: {'C': 1.0280148064410346, 'gamma': 0.060144295357079394}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,879] Trial 53 finished with value: 0.9462450592885375 and parameters: {'C': 9.686208955668668, 'gamma': 0.07118989889223011}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:43,944] Trial 54 finished with value: 0.9727272727272727 and parameters: {'C': 9.524841773926534, 'gamma': 0.03035713424321185}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,000] Trial 55 finished with value: 0.9727272727272727 and parameters: {'C': 9.464001111379849, 'gamma': 0.030650926457890415}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,077] Trial 56 finished with value: 0.9727272727272727 and parameters: {'C': 9.360927342307466, 'gamma': 0.029856958513456554}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,113] Trial 57 finished with value: 0.9727272727272727 and parameters: {'C': 9.358128990085193, 'gamma': 0.027860170824674572}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,178] Trial 58 finished with value: 0.9727272727272727 and parameters: {'C': 9.174505134040542, 'gamma': 0.029778702322600478}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,228] Trial 59 finished with value: 0.9458498023715414 and parameters: {'C': 9.116855949895285, 'gamma': 0.00944541078735824}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,277] Trial 60 finished with value: 0.9458498023715414 and parameters: {'C': 8.47536919341704, 'gamma': 0.00992114585181692}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,354] Trial 61 finished with value: 0.9458498023715414 and parameters: {'C': 8.695798295623732, 'gamma': 0.004859085660530402}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,443] Trial 62 finished with value: 0.9458498023715414 and parameters: {'C': 8.790378750473472, 'gamma': 0.020987173831487068}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,494] Trial 63 finished with value: 0.9636363636363636 and parameters: {'C': 9.141965713829494, 'gamma': 0.02773734826061034}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,576] Trial 65 finished with value: 0.9727272727272727 and parameters: {'C': 9.495161622630711, 'gamma': 0.030119002781737944}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,578] Trial 64 finished with value: 0.9727272727272727 and parameters: {'C': 9.243960679386438, 'gamma': 0.027694853515328525}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,642] Trial 66 finished with value: 0.9458498023715414 and parameters: {'C': 7.632150005225794, 'gamma': 0.016947594206857094}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,713] Trial 67 finished with value: 0.4391304347826087 and parameters: {'C': 7.647174116185948, 'gamma': 2.737417711182608e-06}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,741] Trial 68 finished with value: 0.9636363636363636 and parameters: {'C': 6.744542195315649, 'gamma': 0.06854363382498599}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,810] Trial 69 finished with value: 0.9458498023715414 and parameters: {'C': 6.92947189137059, 'gamma': 0.005724842812358733}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,837] Trial 70 finished with value: 0.9458498023715414 and parameters: {'C': 8.411281123360956, 'gamma': 0.011720968760840259}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,912] Trial 71 finished with value: 0.9545454545454547 and parameters: {'C': 8.416186700404088, 'gamma': 0.029038763440222375}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:44,950] Trial 72 finished with value: 0.9727272727272727 and parameters: {'C': 9.49884302284173, 'gamma': 0.031104357270090335}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,056] Trial 73 finished with value: 0.9727272727272727 and parameters: {'C': 9.50876504359487, 'gamma': 0.03146589357975011}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,082] Trial 74 finished with value: 0.9458498023715414 and parameters: {'C': 9.604724583230288, 'gamma': 0.019918287389920415}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,165] Trial 75 finished with value: 0.9458498023715414 and parameters: {'C': 9.635900107258388, 'gamma': 0.019824129258770112}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,205] Trial 76 finished with value: 0.9462450592885375 and parameters: {'C': 8.968753320743264, 'gamma': 0.06028943355333152}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,297] Trial 77 finished with value: 0.9549407114624506 and parameters: {'C': 8.97536559931187, 'gamma': 0.05840038727800679}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,319] Trial 78 finished with value: 0.9458498023715414 and parameters: {'C': 9.278568406211486, 'gamma': 0.00823236397053385}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,456] Trial 80 finished with value: 0.9458498023715414 and parameters: {'C': 9.75059028691394, 'gamma': 0.09066732517784842}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,538] Trial 79 finished with value: 0.9371541501976285 and parameters: {'C': 9.32589628020607, 'gamma': 0.08981477849431474}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,641] Trial 81 finished with value: 0.9458498023715414 and parameters: {'C': 9.288862768644522, 'gamma': 0.013546740157298502}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,713] Trial 82 finished with value: 0.9727272727272727 and parameters: {'C': 9.390347529428226, 'gamma': 0.031923890107905174}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,797] Trial 83 finished with value: 0.9727272727272727 and parameters: {'C': 9.495286197684838, 'gamma': 0.029388951604054928}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,895] Trial 84 finished with value: 0.9545454545454547 and parameters: {'C': 8.862798350827179, 'gamma': 0.025720138094229395}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:45,983] Trial 85 finished with value: 0.9458498023715414 and parameters: {'C': 8.873388825259074, 'gamma': 0.024379610320913698}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,139] Trial 86 finished with value: 0.9458498023715414 and parameters: {'C': 9.69694774050975, 'gamma': 0.017739493137243042}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,221] Trial 87 finished with value: 0.9549407114624506 and parameters: {'C': 9.862600009092638, 'gamma': 0.01638094428322391}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,283] Trial 88 finished with value: 0.9636363636363636 and parameters: {'C': 9.106000928774115, 'gamma': 0.051120174460950185}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,461] Trial 89 finished with value: 0.9636363636363636 and parameters: {'C': 8.231668875066505, 'gamma': 0.054239336516941135}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,493] Trial 90 finished with value: 0.9727272727272727 and parameters: {'C': 8.579382536818223, 'gamma': 0.033536272085570654}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,584] Trial 91 finished with value: 0.9727272727272727 and parameters: {'C': 8.605910699347643, 'gamma': 0.034398529393941495}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,617] Trial 92 finished with value: 0.9458498023715414 and parameters: {'C': 9.501781566604919, 'gamma': 0.012559016817943306}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,729] Trial 93 finished with value: 0.9458498023715414 and parameters: {'C': 9.526972505776444, 'gamma': 0.01244343007386601}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,779] Trial 94 finished with value: 0.9458498023715414 and parameters: {'C': 9.472758457869169, 'gamma': 0.022954899886941646}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:46,894] Trial 95 finished with value: 0.9545454545454547 and parameters: {'C': 9.116223435055382, 'gamma': 0.02481054124870384}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:47,074] Trial 96 finished with value: 0.7517786561264822 and parameters: {'C': 9.861824129573936, 'gamma': 0.00024420332001262026}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:47,121] Trial 97 finished with value: 0.9371541501976285 and parameters: {'C': 9.79014162812562, 'gamma': 0.07961455156951232}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:47,303] Trial 98 finished with value: 0.9636363636363636 and parameters: {'C': 9.747001416772354, 'gamma': 0.037372721355821044}. Best is trial 24 with value: 0.9727272727272727.\n",
            "[I 2024-01-28 01:20:47,385] Trial 99 finished with value: 0.9549407114624506 and parameters: {'C': 9.285015828121503, 'gamma': 0.03462226401318882}. Best is trial 24 with value: 0.9727272727272727.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'C': 9.416838780443127, 'gamma': 0.027207085506127392}\n",
            "Test set accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    通常のOptunaによるハイパーパラメータチューニングをするときよりも、非常にシンプルになります。"
      ],
      "metadata": {
        "id": "bX2QOM2hf82c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータ探索空間の定義方法\n",
        "    ハイパーパラメータの探索空間は、モデルの学習に大きな影響を与えます。OptunaとOptunaSearchCVでは、非常に柔軟にこの探索空間を定義することが可能です。\n",
        "\n",
        "    OptunaSearchCVでは、param_distributions引数を使用してハイパーパラメータの探索空間を定義します。"
      ],
      "metadata": {
        "id": "YbBk2KN6qN2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Screenshot 2024-01-28 at 10.22.36.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "AKTwj1TqqSN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    以下は、OptunaSearchCVでの指定例です。"
      ],
      "metadata": {
        "id": "siD6SRIyqSPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# param_distributions = {\n",
        "#     'C': optuna.distributions.FloatDistribution(1e-10, 1e+10, log=True),\n",
        "#     'gamma': optuna.distributions.FloatDistribution(1e-10, 1e+1, log=True),\n",
        "#     'kernel': optuna.distributions.CategoricalDistribution(['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "# }"
      ],
      "metadata": {
        "id": "p9VvvLPBq2I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    このように、OptunaSearchCVでは、Optunaの分布を直接指定して、非常に柔軟なハイパーパラメータ探索が可能です。"
      ],
      "metadata": {
        "id": "nTxfOR_UqxGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OptunaSearchCVの高度な設定とテクニック\n",
        "    OptunaSearchCVは、基本的なハイパーパラメータのチューニングだけでなく、高度な設定やテクニックも提供しています。\n",
        "    この章では、プルーニングの活用方法や交差検証との連携について詳しく探ることで、OptunaSearchCVの可能性をさらに引き出す方法を学びます。"
      ],
      "metadata": {
        "id": "nwODYmwSqSWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## プルーニングの活用方法\n",
        "    Optunaの強力な機能の1つが「プルーニング」です。これは、最適化中に非効率的なトライアルを早期に打ち切る技術で、計算リソースを節約するとともに、全体の最適化プロセスを加速します。\n",
        "\n",
        "    OptunaSearchCVを使用する場合、プルーニングはpruner引数を指定することで簡単に活用できます。例えば、メディアンプルーナを使用する場合、次のように設定します。"
      ],
      "metadata": {
        "id": "Ku9zq_5Vqnae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from optuna.integration import OptunaSearchCV\n",
        "# from optuna.pruners import MedianPruner\n",
        "\n",
        "# pruner = MedianPruner()\n",
        "# search = OptunaSearchCV(estimator, param_distributions, pruner=pruner)"
      ],
      "metadata": {
        "id": "Km5RWQrGqs24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 交差検証 (Cross-validation) との連携\n",
        "    OptunaSearchCVは、scikit-learnのGridSearchCVやRandomizedSearchCVと同様に、交差検証をサポートしています。\n",
        "    これにより、モデルの性能評価がより信頼性を持つものとなります。\n",
        "\n",
        "    デフォルトでは、3-fold交差検証が行われますが、cv引数を用いて、異なる分割数（cv=10）やカスタム分割ロジックを持つStratifiedKFoldなどの\n",
        "    交差検証ストラテジを指定（cv=StratifiedKFold(…)）することもできます。"
      ],
      "metadata": {
        "id": "-SyseDHEgN1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# search = OptunaSearchCV(estimator, param_distributions, cv=cv)"
      ],
      "metadata": {
        "id": "_4q4IGeYrHxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    ちなみに、StratifiedKFoldは、scikit-learnの交差検証（Cross-validation）ストラテジの1つで、特に分類問題において有用です。\n",
        "\n",
        "    具体的には、StratifiedKFoldは次のように動作します。\n",
        "\n",
        "    1.元のデータセットのクラスの比率を確認します。\n",
        "    2.データセットをK個の分割に分けますが、このとき各分割が元のクラスの比率を尊重するようにします。\n",
        "\n",
        "    StratifiedKFoldの利点です。\n",
        "\n",
        "    ・不均衡なクラス分布を持つデータセットでのモデルの評価に非常に役立ちます。これは、少数のクラスがテストデータセットに偏らないようにするためです。\n",
        "    ・実際のモデルの性能をより正確に推定することができます。\n",
        "\n",
        "    例えば、2つのクラス（ラベル0と1）を持つデータセットがある場合、StratifiedKFoldを使用すると、各分割での0と1の比率が、元のデータセットの比率とほぼ同じになるようにします。"
      ],
      "metadata": {
        "id": "wJ7_a3q4ln45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OptunaSearchCVの実践例\n",
        "### 実際のデータセットを用いたモデルの最適化\n",
        "    scikit-learnのサンプルデータセット、例えばirisやdiabetesを使用して、OptunaSearchCVを活用したハイパーパラメータチューニングの手順を紹介します。\n",
        "\n",
        "    このデータセットを用いて、例えば決定木やランダムフォレストといったモデルの最適なハイパーパラメータを見つける過程を示します。\n",
        "\n",
        "    1.データセットの読み込みと前処理\n",
        "    2.OptunaSearchCVの設定（目的関数の定義、探索空間の指定など）\n",
        "    3.モデルの最適化実行\n",
        "\n",
        "    最適化が完了した後、結果をどのように解釈し、モデルの性能をどのように評価するかが重要です。\n",
        "\n",
        "    OptunaSearchCVの結果を取得する方法、ベストなハイパーパラメータの値やその性能を確認する方法を紹介します。\n",
        "\n",
        "    1.ベストなハイパーパラメータの取得\n",
        "    2.性能評価の指標に基づく評価\n",
        "    3.結果の視覚化"
      ],
      "metadata": {
        "id": "gBRbdCV3ln7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分類問題（アヤメのデータセット）例\n",
        "    このiris（アヤメ）のデータセットは、3つの異なるアイリスの種類（setosa, versicolor, virginica）の各々に対する50のサンプルからなります。\n",
        "    各サンプルには4つの特徴量（ガクの長さ、ガクの幅、花びらの長さ、花びらの幅）があります。アヤメの種類を予測するタスクが一般的です。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "qB_SyEeLln9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.integration import OptunaSearchCV\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読み込み\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# パラメータの探索空間の定義\n",
        "param_distributions = {\n",
        "    'n_estimators': optuna.distributions.IntDistribution(2, 150),\n",
        "    'max_depth': optuna.distributions.IntDistribution(1, 32, log=True)\n",
        "}\n",
        "\n",
        "# モデルの定義\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# OptunaSearchCVの設定\n",
        "optuna_search = OptunaSearchCV(\n",
        "    clf,\n",
        "    param_distributions,\n",
        "    n_trials=100,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "# モデルの最適化実行\n",
        "optuna_search.fit(X_train, y_train)\n",
        "\n",
        "# 最適化後のベストなパラメータとスコアの表示\n",
        "print(f\"Best parameters: {optuna_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {optuna_search.best_score_:.3f}\")\n",
        "\n",
        "# テストデータに対する評価\n",
        "test_score = optuna_search.score(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_score:.3f}\")\n",
        "\n",
        "# 最適化されたモデルの特徴を取得して表示\n",
        "best_estimator = optuna_search.best_estimator_\n",
        "print(f\"Best estimator: {best_estimator}\")\n",
        "\n",
        "# さらに、Optunaのスタディオブジェクトを取得して、詳細な最適化の結果を分析することも可能です。\n",
        "study = optuna_search.study_\n",
        "print(f\"Number of finished trials: {len(study.trials)}\")\n",
        "print(f\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  Value: {trial.value}\")\n",
        "print(f\"  Params: {trial.params}\")\n",
        "\n",
        "# Optunaのビジュアライゼーション機能を使って、探索の過程を視覚的に確認することもできます。\n",
        "# 以下は、すべてのトライアルの結果をプロットする例です。\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YHbNPo-XmHoZ",
        "outputId": "0871124b-ba90-429b-ec96-73de099b39ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-af983f1eb8b3>:23: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
            "  optuna_search = OptunaSearchCV(\n",
            "[I 2024-01-28 01:28:49,071] A new study created in memory with name: no-name-a31a7ac3-3da5-4d33-8fd7-d80768a9f7e2\n",
            "[I 2024-01-28 01:28:49,688] Trial 0 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 37, 'max_depth': 1}. Best is trial 0 with value: 0.9371740161213845.\n",
            "[I 2024-01-28 01:28:50,563] Trial 1 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 99, 'max_depth': 22}. Best is trial 1 with value: 0.9374110953058322.\n",
            "[I 2024-01-28 01:28:51,003] Trial 2 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 100, 'max_depth': 3}. Best is trial 2 with value: 0.9461830251303937.\n",
            "[I 2024-01-28 01:28:51,662] Trial 3 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 119, 'max_depth': 28}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:52,301] Trial 4 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 142, 'max_depth': 9}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:52,535] Trial 5 finished with value: 0.9281650071123756 and parameters: {'n_estimators': 45, 'max_depth': 2}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:52,560] Trial 6 finished with value: 0.8933143669985775 and parameters: {'n_estimators': 3, 'max_depth': 3}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:53,185] Trial 7 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 141, 'max_depth': 15}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:53,405] Trial 8 finished with value: 0.954954954954955 and parameters: {'n_estimators': 48, 'max_depth': 1}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:53,906] Trial 9 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 110, 'max_depth': 10}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:54,246] Trial 10 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 70, 'max_depth': 31}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:54,629] Trial 11 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 75, 'max_depth': 31}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:54,978] Trial 12 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 75, 'max_depth': 8}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:55,537] Trial 13 finished with value: 0.9284020862968232 and parameters: {'n_estimators': 120, 'max_depth': 32}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:55,931] Trial 14 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 83, 'max_depth': 16}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:56,233] Trial 15 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 62, 'max_depth': 6}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:56,822] Trial 16 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 123, 'max_depth': 18}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:56,910] Trial 17 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 15, 'max_depth': 6}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:57,319] Trial 18 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 88, 'max_depth': 12}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:57,598] Trial 19 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 58, 'max_depth': 23}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:57,768] Trial 20 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 29, 'max_depth': 5}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:58,034] Trial 21 finished with value: 0.936936936936937 and parameters: {'n_estimators': 54, 'max_depth': 1}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:58,579] Trial 22 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 69, 'max_depth': 2}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:58,992] Trial 23 finished with value: 0.9281650071123756 and parameters: {'n_estimators': 67, 'max_depth': 2}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:28:59,715] Trial 24 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 93, 'max_depth': 2}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:00,501] Trial 25 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 125, 'max_depth': 3}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:02,175] Trial 26 finished with value: 0.9459459459459459 and parameters: {'n_estimators': 74, 'max_depth': 25}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:04,237] Trial 27 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 108, 'max_depth': 13}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:05,398] Trial 28 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 85, 'max_depth': 4}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:05,700] Trial 29 finished with value: 0.8492176386913228 and parameters: {'n_estimators': 31, 'max_depth': 1}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:05,890] Trial 30 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 37, 'max_depth': 20}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:06,220] Trial 31 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 66, 'max_depth': 1}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:06,473] Trial 32 finished with value: 0.9459459459459459 and parameters: {'n_estimators': 51, 'max_depth': 2}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:06,846] Trial 33 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 47, 'max_depth': 26}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:07,255] Trial 34 finished with value: 0.9459459459459459 and parameters: {'n_estimators': 43, 'max_depth': 1}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:07,489] Trial 35 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 20, 'max_depth': 4}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:08,187] Trial 36 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 100, 'max_depth': 2}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:09,448] Trial 37 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 149, 'max_depth': 3}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:09,916] Trial 38 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 66, 'max_depth': 8}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:10,251] Trial 39 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 68, 'max_depth': 13}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:10,713] Trial 40 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 96, 'max_depth': 8}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:10,985] Trial 41 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 57, 'max_depth': 29}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:11,373] Trial 42 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 78, 'max_depth': 20}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:11,701] Trial 43 finished with value: 0.954954954954955 and parameters: {'n_estimators': 71, 'max_depth': 3}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:11,984] Trial 44 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 61, 'max_depth': 10}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:12,595] Trial 45 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 132, 'max_depth': 16}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:13,099] Trial 46 finished with value: 0.9464201043148411 and parameters: {'n_estimators': 112, 'max_depth': 6}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:13,480] Trial 47 finished with value: 0.9464201043148411 and parameters: {'n_estimators': 79, 'max_depth': 8}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:13,679] Trial 48 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 40, 'max_depth': 30}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:13,929] Trial 49 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 49, 'max_depth': 24}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:14,336] Trial 50 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 84, 'max_depth': 19}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:14,874] Trial 51 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 72, 'max_depth': 3}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:15,356] Trial 52 finished with value: 0.9284020862968232 and parameters: {'n_estimators': 62, 'max_depth': 32}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:16,043] Trial 53 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 88, 'max_depth': 5}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:16,516] Trial 54 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 55, 'max_depth': 5}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:16,886] Trial 55 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 72, 'max_depth': 3}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:17,247] Trial 56 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 79, 'max_depth': 4}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:17,743] Trial 57 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 106, 'max_depth': 11}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:18,042] Trial 58 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 64, 'max_depth': 27}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:18,463] Trial 59 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 91, 'max_depth': 15}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:18,794] Trial 60 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 69, 'max_depth': 2}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:19,131] Trial 61 finished with value: 0.9284020862968232 and parameters: {'n_estimators': 71, 'max_depth': 7}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:19,419] Trial 62 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 59, 'max_depth': 3}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:19,773] Trial 63 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 75, 'max_depth': 3}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:20,024] Trial 64 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 52, 'max_depth': 17}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:20,420] Trial 65 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 81, 'max_depth': 4}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:20,578] Trial 66 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 30, 'max_depth': 5}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:20,884] Trial 67 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 64, 'max_depth': 2}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:21,097] Trial 68 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 42, 'max_depth': 22}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:21,277] Trial 69 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 35, 'max_depth': 7}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:21,621] Trial 70 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 74, 'max_depth': 13}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:22,156] Trial 71 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 115, 'max_depth': 6}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:22,787] Trial 72 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 132, 'max_depth': 7}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:23,320] Trial 73 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 115, 'max_depth': 5}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:23,905] Trial 74 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 128, 'max_depth': 4}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:24,450] Trial 75 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 119, 'max_depth': 6}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:24,795] Trial 76 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 68, 'max_depth': 10}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:25,420] Trial 77 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 138, 'max_depth': 22}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:25,883] Trial 78 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 96, 'max_depth': 28}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:26,324] Trial 79 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 95, 'max_depth': 24}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:26,959] Trial 80 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 105, 'max_depth': 28}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:27,673] Trial 81 finished with value: 0.9284020862968232 and parameters: {'n_estimators': 95, 'max_depth': 24}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:28,399] Trial 82 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 88, 'max_depth': 26}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:29,021] Trial 83 finished with value: 0.9464201043148411 and parameters: {'n_estimators': 102, 'max_depth': 30}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:29,144] Trial 84 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 22, 'max_depth': 20}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:29,207] Trial 85 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 7, 'max_depth': 20}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:29,263] Trial 86 finished with value: 0.9193930772878142 and parameters: {'n_estimators': 6, 'max_depth': 22}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:29,710] Trial 87 finished with value: 0.9464201043148411 and parameters: {'n_estimators': 97, 'max_depth': 17}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:29,836] Trial 88 finished with value: 0.9371740161213845 and parameters: {'n_estimators': 22, 'max_depth': 27}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:30,260] Trial 89 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 85, 'max_depth': 32}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:30,359] Trial 90 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 16, 'max_depth': 19}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:30,699] Trial 91 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 71, 'max_depth': 24}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:31,063] Trial 92 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 76, 'max_depth': 29}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:31,285] Trial 93 finished with value: 0.9374110953058322 and parameters: {'n_estimators': 46, 'max_depth': 15}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:31,651] Trial 94 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 81, 'max_depth': 21}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:32,048] Trial 95 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 81, 'max_depth': 25}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:32,460] Trial 96 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 87, 'max_depth': 21}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:32,883] Trial 97 finished with value: 0.9461830251303937 and parameters: {'n_estimators': 93, 'max_depth': 18}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:33,177] Trial 98 finished with value: 0.9551920341394027 and parameters: {'n_estimators': 57, 'max_depth': 14}. Best is trial 3 with value: 0.9551920341394027.\n",
            "[I 2024-01-28 01:29:33,489] Trial 99 finished with value: 0.9464201043148411 and parameters: {'n_estimators': 65, 'max_depth': 14}. Best is trial 3 with value: 0.9551920341394027.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'n_estimators': 119, 'max_depth': 28}\n",
            "Best cross-validation score: 0.955\n",
            "Test accuracy: 1.000\n",
            "Best estimator: RandomForestClassifier(max_depth=28, n_estimators=119)\n",
            "Number of finished trials: 100\n",
            "Best trial:\n",
            "  Value: 0.9551920341394027\n",
            "  Params: {'n_estimators': 119, 'max_depth': 28}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f7426b8a-1a41-4c50-81ce-4153740fa882\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f7426b8a-1a41-4c50-81ce-4153740fa882\")) {                    Plotly.newPlot(                        \"f7426b8a-1a41-4c50-81ce-4153740fa882\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.9371740161213845,0.9374110953058322,0.9461830251303937,0.9551920341394027,0.9461830251303937,0.9281650071123756,0.8933143669985775,0.9461830251303937,0.954954954954955,0.9461830251303937,0.9551920341394027,0.9461830251303937,0.9374110953058322,0.9284020862968232,0.9461830251303937,0.9461830251303937,0.9461830251303937,0.9461830251303937,0.9461830251303937,0.9461830251303937,0.9371740161213845,0.936936936936937,0.9551920341394027,0.9281650071123756,0.9371740161213845,0.9371740161213845,0.9459459459459459,0.9461830251303937,0.9461830251303937,0.8492176386913228,0.9374110953058322,0.9371740161213845,0.9459459459459459,0.9461830251303937,0.9459459459459459,0.9461830251303937,0.9371740161213845,0.9461830251303937,0.9551920341394027,0.9374110953058322,0.9461830251303937,0.9374110953058322,0.9461830251303937,0.954954954954955,0.9374110953058322,0.9461830251303937,0.9464201043148411,0.9464201043148411,0.9461830251303937,0.9461830251303937,0.9374110953058322,0.9551920341394027,0.9284020862968232,0.9461830251303937,0.9461830251303937,0.9374110953058322,0.9461830251303937,0.9374110953058322,0.9371740161213845,0.9374110953058322,0.9371740161213845,0.9284020862968232,0.9461830251303937,0.9461830251303937,0.9371740161213845,0.9374110953058322,0.9461830251303937,0.9371740161213845,0.9374110953058322,0.9461830251303937,0.9374110953058322,0.9461830251303937,0.9371740161213845,0.9461830251303937,0.9371740161213845,0.9461830251303937,0.9461830251303937,0.9461830251303937,0.9551920341394027,0.9551920341394027,0.9461830251303937,0.9284020862968232,0.9461830251303937,0.9464201043148411,0.9551920341394027,0.9371740161213845,0.9193930772878142,0.9464201043148411,0.9371740161213845,0.9461830251303937,0.9461830251303937,0.9461830251303937,0.9374110953058322,0.9374110953058322,0.9551920341394027,0.9461830251303937,0.9461830251303937,0.9461830251303937,0.9551920341394027,0.9464201043148411],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.9371740161213845,0.9374110953058322,0.9461830251303937,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027,0.9551920341394027],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f7426b8a-1a41-4c50-81ce-4153740fa882');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    このコードを実行することで、irisデータセット上でのランダムフォレストモデルのベストなハイパーパラメータが得られます。\n",
        "    OptunaSearchCVは、内部で指定されたトライアル数（この例では100回）だけハイパーパラメータの組み合わせを試し、最も良いスコアを持つ組み合わせを選択します。\n",
        "\n",
        "    さらに、最適化されたモデルのテストデータに対する正確性を計算して表示します。\n",
        "    さらに、最適化されたモデルの具体的な特徴や、Optunaのスタディオブジェクトを通じて、ハイパーパラメータ探索の詳細な結果を取得・表示します。\n",
        "    最後に、Optunaのビジュアライゼーション機能を使用して、探索の過程を視覚的に確認することができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "BNN3iKP_rxm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 回帰問題（糖尿病のデータセット）例\n",
        "    この糖尿病（diabetes）のデータセットは、糖尿病患者の情報を基にした10の特徴量を持つ、442人の糖尿病患者のデータです。目的変数は、1年後の疾患進行の定量的測定値です。\n",
        "\n",
        "    以下、コードです。"
      ],
      "metadata": {
        "id": "zrtrV0o_l8lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.integration import OptunaSearchCV\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# diabetes データセットの読み込み\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# OptunaSearchCVを定義\n",
        "param_distributions = {\n",
        "    'n_estimators': optuna.distributions.IntDistribution(2, 150),\n",
        "    'max_depth': optuna.distributions.IntDistribution(1, 32),\n",
        "    'min_samples_split': optuna.distributions.FloatDistribution(0.1, 1),\n",
        "    'min_samples_leaf': optuna.distributions.FloatDistribution(0.1, 0.5),\n",
        "    'max_features': optuna.distributions.CategoricalDistribution(['auto', 'sqrt', 'log2'])\n",
        "}\n",
        "\n",
        "clf = RandomForestRegressor(random_state=42)\n",
        "optuna_search = OptunaSearchCV(\n",
        "    clf, param_distributions,\n",
        "    n_trials=100,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# 最適化の実行\n",
        "optuna_search.fit(X_train, y_train)\n",
        "\n",
        "# テストデータに対する評価\n",
        "y_pred = optuna_search.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Test MSE: {mse:.3f}\")\n",
        "\n",
        "# 最適化されたモデルの特徴を表示\n",
        "best_estimator = optuna_search.best_estimator_\n",
        "print(f\"Best estimator: {best_estimator}\")\n",
        "\n",
        "# Optunaのスタディオブジェクトを取得し、詳細な最適化の結果を分析\n",
        "study = optuna_search.study_\n",
        "print(f\"Number of finished trials: {len(study.trials)}\")\n",
        "print(f\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  Value: {trial.value}\")\n",
        "print(f\"  Params: {trial.params}\")\n",
        "\n",
        "# 探索の過程を視覚的に確認\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uPFXA5dPsGqU",
        "outputId": "ee2d5326-f00f-4f11-d4ac-de9956587648"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f248b7563619>:24: ExperimentalWarning:\n",
            "\n",
            "OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
            "\n",
            "[I 2024-01-28 01:30:40,952] A new study created in memory with name: no-name-70bb4bba-8f4d-4be0-a0b0-b6e028c0f039\n",
            "[I 2024-01-28 01:30:40,954] Searching the best hyperparameters using 353 samples...\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:41,258] Trial 0 finished with value: 0.3327181569191832 and parameters: {'n_estimators': 69, 'max_depth': 27, 'min_samples_split': 0.1621462067862438, 'min_samples_leaf': 0.22777890041590695, 'max_features': 'auto'}. Best is trial 0 with value: 0.3327181569191832.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:41,380] Trial 1 finished with value: 0.3362061919067875 and parameters: {'n_estimators': 26, 'max_depth': 6, 'min_samples_split': 0.3866907188997434, 'min_samples_leaf': 0.23962706528454328, 'max_features': 'auto'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "[I 2024-01-28 01:30:41,607] Trial 2 finished with value: -0.021966568118627183 and parameters: {'n_estimators': 59, 'max_depth': 16, 'min_samples_split': 0.8712711370321202, 'min_samples_leaf': 0.4894970840167867, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "[I 2024-01-28 01:30:42,159] Trial 3 finished with value: 0.26988966568828426 and parameters: {'n_estimators': 139, 'max_depth': 29, 'min_samples_split': 0.1817582823436586, 'min_samples_leaf': 0.2821462080016537, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "[I 2024-01-28 01:30:42,232] Trial 4 finished with value: 0.10515591582898043 and parameters: {'n_estimators': 16, 'max_depth': 23, 'min_samples_split': 0.5459339028021267, 'min_samples_leaf': 0.31480439465838295, 'max_features': 'log2'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "[I 2024-01-28 01:30:42,265] Trial 5 finished with value: -0.02168248842203953 and parameters: {'n_estimators': 6, 'max_depth': 24, 'min_samples_split': 0.8808304703494815, 'min_samples_leaf': 0.2905439553258185, 'max_features': 'log2'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "[I 2024-01-28 01:30:42,784] Trial 6 finished with value: 0.19819725160063537 and parameters: {'n_estimators': 137, 'max_depth': 30, 'min_samples_split': 0.22519984476480417, 'min_samples_leaf': 0.30735381353897473, 'max_features': 'log2'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "[I 2024-01-28 01:30:43,287] Trial 7 finished with value: -0.021488741264716005 and parameters: {'n_estimators': 133, 'max_depth': 26, 'min_samples_split': 0.5095409402907529, 'min_samples_leaf': 0.3564938934958255, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "[I 2024-01-28 01:30:43,364] Trial 8 finished with value: -0.021996752566249 and parameters: {'n_estimators': 17, 'max_depth': 16, 'min_samples_split': 0.27524858910682354, 'min_samples_leaf': 0.48813714412532927, 'max_features': 'log2'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:43,968] Trial 9 finished with value: -0.02122230007090331 and parameters: {'n_estimators': 149, 'max_depth': 27, 'min_samples_split': 0.4064640319846343, 'min_samples_leaf': 0.41452300788555185, 'max_features': 'auto'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:44,166] Trial 10 finished with value: -0.021688132864674747 and parameters: {'n_estimators': 43, 'max_depth': 4, 'min_samples_split': 0.7397034631346565, 'min_samples_leaf': 0.12491435073950766, 'max_features': 'auto'}. Best is trial 1 with value: 0.3362061919067875.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:44,630] Trial 11 finished with value: 0.3609366992250836 and parameters: {'n_estimators': 98, 'max_depth': 2, 'min_samples_split': 0.10510564009948964, 'min_samples_leaf': 0.18390018685492987, 'max_features': 'auto'}. Best is trial 11 with value: 0.3609366992250836.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:45,105] Trial 12 finished with value: 0.3360183966675572 and parameters: {'n_estimators': 104, 'max_depth': 1, 'min_samples_split': 0.3623989068805321, 'min_samples_leaf': 0.16629608490786185, 'max_features': 'auto'}. Best is trial 11 with value: 0.3609366992250836.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:45,587] Trial 13 finished with value: -0.021784091680791946 and parameters: {'n_estimators': 110, 'max_depth': 9, 'min_samples_split': 0.6998020351018992, 'min_samples_leaf': 0.20505408676242223, 'max_features': 'auto'}. Best is trial 11 with value: 0.3609366992250836.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:46,053] Trial 14 finished with value: 0.40579313353557867 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 0.12672678697027023, 'min_samples_leaf': 0.10357351835812598, 'max_features': 'auto'}. Best is trial 14 with value: 0.40579313353557867.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:46,522] Trial 15 finished with value: 0.40720469091781436 and parameters: {'n_estimators': 94, 'max_depth': 11, 'min_samples_split': 0.1094834497925608, 'min_samples_leaf': 0.10119184061268528, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:46,952] Trial 16 finished with value: 0.3815682941655329 and parameters: {'n_estimators': 87, 'max_depth': 11, 'min_samples_split': 0.2905810005681179, 'min_samples_leaf': 0.11494563931991945, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:47,509] Trial 17 finished with value: -0.021500452040449963 and parameters: {'n_estimators': 120, 'max_depth': 12, 'min_samples_split': 0.9853035920009846, 'min_samples_leaf': 0.14852399848373105, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:47,952] Trial 18 finished with value: 0.4018654586571666 and parameters: {'n_estimators': 90, 'max_depth': 19, 'min_samples_split': 0.153693441512309, 'min_samples_leaf': 0.1151813558457659, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "[I 2024-01-28 01:30:48,458] Trial 19 finished with value: 0.32475969161033363 and parameters: {'n_estimators': 75, 'max_depth': 8, 'min_samples_split': 0.4676402405260528, 'min_samples_leaf': 0.10354762642290828, 'max_features': 'sqrt'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:49,650] Trial 20 finished with value: 0.1220168533237398 and parameters: {'n_estimators': 118, 'max_depth': 14, 'min_samples_split': 0.644533416811961, 'min_samples_leaf': 0.15347722412980186, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:50,667] Trial 21 finished with value: 0.4050082290199338 and parameters: {'n_estimators': 89, 'max_depth': 20, 'min_samples_split': 0.10106448792957654, 'min_samples_leaf': 0.10902307034372961, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:51,176] Trial 22 finished with value: 0.3544893181545586 and parameters: {'n_estimators': 56, 'max_depth': 20, 'min_samples_split': 0.10881300950841909, 'min_samples_leaf': 0.1967370413132483, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:51,887] Trial 23 finished with value: 0.38423317894632025 and parameters: {'n_estimators': 85, 'max_depth': 12, 'min_samples_split': 0.2609979330231158, 'min_samples_leaf': 0.14687525078666747, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:52,269] Trial 24 finished with value: 0.33209525796518485 and parameters: {'n_estimators': 66, 'max_depth': 19, 'min_samples_split': 0.3210132720746075, 'min_samples_leaf': 0.2455467152172317, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:52,756] Trial 25 finished with value: 0.40647327164828884 and parameters: {'n_estimators': 96, 'max_depth': 8, 'min_samples_split': 0.20659984339887727, 'min_samples_leaf': 0.10338675071091943, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:53,348] Trial 26 finished with value: 0.38736314717541953 and parameters: {'n_estimators': 117, 'max_depth': 7, 'min_samples_split': 0.20288484551774036, 'min_samples_leaf': 0.13858375017095745, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:53,810] Trial 27 finished with value: 0.3634241446484581 and parameters: {'n_estimators': 102, 'max_depth': 5, 'min_samples_split': 0.21698986262100578, 'min_samples_leaf': 0.17803562875837992, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "[I 2024-01-28 01:30:54,006] Trial 28 finished with value: -0.021324005357352387 and parameters: {'n_estimators': 45, 'max_depth': 10, 'min_samples_split': 0.327792644050498, 'min_samples_leaf': 0.3771588346206108, 'max_features': 'log2'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "[I 2024-01-28 01:30:54,347] Trial 29 finished with value: 0.3085331002821868 and parameters: {'n_estimators': 75, 'max_depth': 13, 'min_samples_split': 0.1641247739509034, 'min_samples_leaf': 0.21431508895936052, 'max_features': 'sqrt'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:54,770] Trial 30 finished with value: 0.3303257778660797 and parameters: {'n_estimators': 96, 'max_depth': 3, 'min_samples_split': 0.41813190462024485, 'min_samples_leaf': 0.2555708947967127, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:55,433] Trial 31 finished with value: 0.40715253365435977 and parameters: {'n_estimators': 83, 'max_depth': 14, 'min_samples_split': 0.10300754184500827, 'min_samples_leaf': 0.10275018413313279, 'max_features': 'auto'}. Best is trial 15 with value: 0.40720469091781436.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:56,195] Trial 32 finished with value: 0.4077621494575155 and parameters: {'n_estimators': 81, 'max_depth': 14, 'min_samples_split': 0.1544734099103134, 'min_samples_leaf': 0.10183397974314348, 'max_features': 'auto'}. Best is trial 32 with value: 0.4077621494575155.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:56,793] Trial 33 finished with value: 0.3904725895759203 and parameters: {'n_estimators': 80, 'max_depth': 14, 'min_samples_split': 0.24097890978239198, 'min_samples_leaf': 0.13312304836622338, 'max_features': 'auto'}. Best is trial 32 with value: 0.4077621494575155.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:57,120] Trial 34 finished with value: 0.36342103356977695 and parameters: {'n_estimators': 65, 'max_depth': 16, 'min_samples_split': 0.17796112519395615, 'min_samples_leaf': 0.17418654804566, 'max_features': 'auto'}. Best is trial 32 with value: 0.4077621494575155.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:30:57,787] Trial 35 finished with value: 0.39095743715158204 and parameters: {'n_estimators': 107, 'max_depth': 6, 'min_samples_split': 0.16104900870439623, 'min_samples_leaf': 0.13518856554822925, 'max_features': 'auto'}. Best is trial 32 with value: 0.4077621494575155.\n",
            "[I 2024-01-28 01:30:58,099] Trial 36 finished with value: 0.4148177112674587 and parameters: {'n_estimators': 52, 'max_depth': 17, 'min_samples_split': 0.20650593234907547, 'min_samples_leaf': 0.10022239302145346, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:30:58,484] Trial 37 finished with value: 0.3095480861737048 and parameters: {'n_estimators': 50, 'max_depth': 18, 'min_samples_split': 0.33656034724024897, 'min_samples_leaf': 0.22893397380688002, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:30:58,779] Trial 38 finished with value: 0.37053958427871336 and parameters: {'n_estimators': 34, 'max_depth': 15, 'min_samples_split': 0.2791165365989754, 'min_samples_leaf': 0.16096936780883028, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:30:59,265] Trial 39 finished with value: 0.28814214281627304 and parameters: {'n_estimators': 58, 'max_depth': 23, 'min_samples_split': 0.15304236719802983, 'min_samples_leaf': 0.2644686498988338, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:30:59,819] Trial 40 finished with value: -0.02142301156948682 and parameters: {'n_estimators': 70, 'max_depth': 17, 'min_samples_split': 0.6211713021189136, 'min_samples_leaf': 0.4501168088018922, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:00,198] Trial 41 finished with value: 0.41296630186159256 and parameters: {'n_estimators': 81, 'max_depth': 12, 'min_samples_split': 0.2116674566057508, 'min_samples_leaf': 0.10067379622150005, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:00,665] Trial 42 finished with value: 0.39240070799317683 and parameters: {'n_estimators': 83, 'max_depth': 11, 'min_samples_split': 0.23906978296306994, 'min_samples_leaf': 0.1262362300733561, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:01,179] Trial 43 finished with value: 0.39041709983217215 and parameters: {'n_estimators': 72, 'max_depth': 14, 'min_samples_split': 0.19664489584428174, 'min_samples_leaf': 0.12397970229548513, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:01,781] Trial 44 finished with value: 0.37489163949793863 and parameters: {'n_estimators': 80, 'max_depth': 21, 'min_samples_split': 0.1413513732119739, 'min_samples_leaf': 0.15169478032353179, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:02,118] Trial 45 finished with value: 0.3507392791499237 and parameters: {'n_estimators': 36, 'max_depth': 32, 'min_samples_split': 0.1002749998945133, 'min_samples_leaf': 0.19033960656659166, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:02,635] Trial 46 finished with value: 0.38347611022127265 and parameters: {'n_estimators': 65, 'max_depth': 17, 'min_samples_split': 0.298760401917449, 'min_samples_leaf': 0.10035529919068327, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:02,874] Trial 47 finished with value: 0.037651027370353196 and parameters: {'n_estimators': 54, 'max_depth': 12, 'min_samples_split': 0.44283091415262854, 'min_samples_leaf': 0.3229510757494634, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:03,010] Trial 48 finished with value: 0.34829916993222043 and parameters: {'n_estimators': 24, 'max_depth': 15, 'min_samples_split': 0.37531922797375283, 'min_samples_leaf': 0.12568006544535923, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:03,495] Trial 49 finished with value: 0.36088902289129066 and parameters: {'n_estimators': 113, 'max_depth': 10, 'min_samples_split': 0.24766521392050594, 'min_samples_leaf': 0.16774525636096665, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:03,901] Trial 50 finished with value: -0.02154438604187788 and parameters: {'n_estimators': 101, 'max_depth': 13, 'min_samples_split': 0.7903081909449771, 'min_samples_leaf': 0.12113634771545376, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:04,518] Trial 51 finished with value: 0.4050637216722979 and parameters: {'n_estimators': 125, 'max_depth': 8, 'min_samples_split': 0.19725982719321672, 'min_samples_leaf': 0.11283305619370365, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:04,989] Trial 52 finished with value: 0.4064724733763531 and parameters: {'n_estimators': 95, 'max_depth': 9, 'min_samples_split': 0.13003722490771272, 'min_samples_leaf': 0.10361020523093789, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:05,572] Trial 53 finished with value: 0.3858370645167861 and parameters: {'n_estimators': 78, 'max_depth': 15, 'min_samples_split': 0.21589244654657214, 'min_samples_leaf': 0.14057274842845735, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:06,238] Trial 54 finished with value: 0.4069724701959802 and parameters: {'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 0.1800743500545266, 'min_samples_leaf': 0.10135906756177118, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:06,771] Trial 55 finished with value: 0.3882532295238659 and parameters: {'n_estimators': 87, 'max_depth': 11, 'min_samples_split': 0.13171506582263548, 'min_samples_leaf': 0.14112480408895112, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:06,900] Trial 56 finished with value: 0.24864601950574713 and parameters: {'n_estimators': 2, 'max_depth': 13, 'min_samples_split': 0.17477773789404522, 'min_samples_leaf': 0.1601537271316672, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:07,458] Trial 57 finished with value: 0.3889689154896369 and parameters: {'n_estimators': 91, 'max_depth': 18, 'min_samples_split': 0.27270453906124437, 'min_samples_leaf': 0.11344057507674338, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:08,073] Trial 58 finished with value: 0.3962916896268232 and parameters: {'n_estimators': 64, 'max_depth': 10, 'min_samples_split': 0.12981285770213224, 'min_samples_leaf': 0.12380950034195343, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:08,731] Trial 59 finished with value: 0.33200093413484977 and parameters: {'n_estimators': 72, 'max_depth': 16, 'min_samples_split': 0.5214967070414676, 'min_samples_leaf': 0.15081110743622198, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:09,216] Trial 60 finished with value: 0.41207541191043323 and parameters: {'n_estimators': 83, 'max_depth': 12, 'min_samples_split': 0.17545101863476426, 'min_samples_leaf': 0.10264484860436186, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:09,700] Trial 61 finished with value: 0.4142813353043173 and parameters: {'n_estimators': 86, 'max_depth': 13, 'min_samples_split': 0.17979962405629002, 'min_samples_leaf': 0.10042867217342603, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:10,249] Trial 62 finished with value: 0.40393024384382664 and parameters: {'n_estimators': 83, 'max_depth': 13, 'min_samples_split': 0.22813556075134062, 'min_samples_leaf': 0.11383521145993823, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:10,675] Trial 63 finished with value: 0.3866607762970357 and parameters: {'n_estimators': 76, 'max_depth': 14, 'min_samples_split': 0.10473273619721621, 'min_samples_leaf': 0.13356833942277332, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:11,403] Trial 64 finished with value: 0.3960264164024605 and parameters: {'n_estimators': 100, 'max_depth': 12, 'min_samples_split': 0.15643484062952479, 'min_samples_leaf': 0.11935859146574487, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:12,101] Trial 65 finished with value: 0.3873937787323957 and parameters: {'n_estimators': 84, 'max_depth': 15, 'min_samples_split': 0.29556154124875206, 'min_samples_leaf': 0.10155603799246736, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:12,692] Trial 66 finished with value: 0.3845796548063536 and parameters: {'n_estimators': 105, 'max_depth': 18, 'min_samples_split': 0.18552706370732414, 'min_samples_leaf': 0.13502484820598368, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:13,385] Trial 67 finished with value: 0.39818213364210225 and parameters: {'n_estimators': 93, 'max_depth': 9, 'min_samples_split': 0.2569184238377074, 'min_samples_leaf': 0.11273155004859722, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:13,941] Trial 68 finished with value: -0.021757891373665128 and parameters: {'n_estimators': 81, 'max_depth': 16, 'min_samples_split': 0.3533457304485521, 'min_samples_leaf': 0.3587151330205743, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:14,410] Trial 69 finished with value: -0.02199529055506762 and parameters: {'n_estimators': 62, 'max_depth': 12, 'min_samples_split': 0.9644895405045015, 'min_samples_leaf': 0.20500210974885213, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:14,886] Trial 70 finished with value: 0.3762784687690626 and parameters: {'n_estimators': 69, 'max_depth': 7, 'min_samples_split': 0.12972298099088853, 'min_samples_leaf': 0.14683789948580178, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:15,339] Trial 71 finished with value: 0.4082671611919115 and parameters: {'n_estimators': 87, 'max_depth': 10, 'min_samples_split': 0.17941467011304102, 'min_samples_leaf': 0.10082509353855182, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:15,719] Trial 72 finished with value: 0.3929281835894935 and parameters: {'n_estimators': 75, 'max_depth': 14, 'min_samples_split': 0.22143236385413384, 'min_samples_leaf': 0.12954241221125215, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:16,119] Trial 73 finished with value: 0.4010878672894241 and parameters: {'n_estimators': 86, 'max_depth': 10, 'min_samples_split': 0.1617825578531099, 'min_samples_leaf': 0.1149482312261936, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:16,682] Trial 74 finished with value: 0.407605657539742 and parameters: {'n_estimators': 97, 'max_depth': 13, 'min_samples_split': 0.20024367119812697, 'min_samples_leaf': 0.10015624721939259, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:17,546] Trial 75 finished with value: 0.37493167801409816 and parameters: {'n_estimators': 108, 'max_depth': 12, 'min_samples_split': 0.1951690986021326, 'min_samples_leaf': 0.1602611176800649, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:18,349] Trial 76 finished with value: -0.02173015176052943 and parameters: {'n_estimators': 97, 'max_depth': 11, 'min_samples_split': 0.31488201065488464, 'min_samples_leaf': 0.49881724126684546, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:18,856] Trial 77 finished with value: 0.39809154940215025 and parameters: {'n_estimators': 91, 'max_depth': 13, 'min_samples_split': 0.2588235849343325, 'min_samples_leaf': 0.11192786782290502, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:19,560] Trial 78 finished with value: 0.38930266349173764 and parameters: {'n_estimators': 88, 'max_depth': 7, 'min_samples_split': 0.22927381804726144, 'min_samples_leaf': 0.1290242702336371, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:20,278] Trial 79 finished with value: 0.3636664308684366 and parameters: {'n_estimators': 103, 'max_depth': 9, 'min_samples_split': 0.15133113050091385, 'min_samples_leaf': 0.17606026988696472, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:21,029] Trial 80 finished with value: 0.30280250964403993 and parameters: {'n_estimators': 112, 'max_depth': 17, 'min_samples_split': 0.5809151285271086, 'min_samples_leaf': 0.10028514946064905, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:21,696] Trial 81 finished with value: 0.4017976295580084 and parameters: {'n_estimators': 79, 'max_depth': 15, 'min_samples_split': 0.12510689898923355, 'min_samples_leaf': 0.11770815119604276, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:22,558] Trial 82 finished with value: 0.38772172611202516 and parameters: {'n_estimators': 94, 'max_depth': 14, 'min_samples_split': 0.1813950546471183, 'min_samples_leaf': 0.14187867974813445, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:23,412] Trial 83 finished with value: 0.40804878124768357 and parameters: {'n_estimators': 150, 'max_depth': 12, 'min_samples_split': 0.20966134767549685, 'min_samples_leaf': 0.10016815795490837, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:24,120] Trial 84 finished with value: 0.39931498206157096 and parameters: {'n_estimators': 150, 'max_depth': 13, 'min_samples_split': 0.20545056069466544, 'min_samples_leaf': 0.12390594292759169, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:24,767] Trial 85 finished with value: 0.40430868725317115 and parameters: {'n_estimators': 132, 'max_depth': 11, 'min_samples_split': 0.23308270133397133, 'min_samples_leaf': 0.10868462478456786, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:25,359] Trial 86 finished with value: 0.3821458611463951 and parameters: {'n_estimators': 49, 'max_depth': 12, 'min_samples_split': 0.2884202277137104, 'min_samples_leaf': 0.1307349697279927, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:26,984] Trial 87 finished with value: -0.021184414004724594 and parameters: {'n_estimators': 142, 'max_depth': 10, 'min_samples_split': 0.1679483999478926, 'min_samples_leaf': 0.46567322343428424, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:27,898] Trial 88 finished with value: 0.40748463263852946 and parameters: {'n_estimators': 144, 'max_depth': 10, 'min_samples_split': 0.20862731549805216, 'min_samples_leaf': 0.11102207591941585, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:28,837] Trial 89 finished with value: 0.39120377659337974 and parameters: {'n_estimators': 145, 'max_depth': 8, 'min_samples_split': 0.27230999331895744, 'min_samples_leaf': 0.10927277509195149, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:29,729] Trial 90 finished with value: 0.3780993048344225 and parameters: {'n_estimators': 135, 'max_depth': 6, 'min_samples_split': 0.2081233866008971, 'min_samples_leaf': 0.1452932944468966, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:30,886] Trial 91 finished with value: 0.40762229061235483 and parameters: {'n_estimators': 140, 'max_depth': 11, 'min_samples_split': 0.1477601113862902, 'min_samples_leaf': 0.10050820933185306, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:31,607] Trial 92 finished with value: 0.4011192641826753 and parameters: {'n_estimators': 145, 'max_depth': 11, 'min_samples_split': 0.2411537412165264, 'min_samples_leaf': 0.1204381975525059, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:32,228] Trial 93 finished with value: 0.40625875963934344 and parameters: {'n_estimators': 124, 'max_depth': 10, 'min_samples_split': 0.14505429140162848, 'min_samples_leaf': 0.10026393497691319, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:32,923] Trial 94 finished with value: 0.40596528157137407 and parameters: {'n_estimators': 139, 'max_depth': 9, 'min_samples_split': 0.1754420787299077, 'min_samples_leaf': 0.10697088297469703, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:33,616] Trial 95 finished with value: 0.31372540598558035 and parameters: {'n_estimators': 148, 'max_depth': 13, 'min_samples_split': 0.19415102519701216, 'min_samples_leaf': 0.2987411157804713, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:34,255] Trial 96 finished with value: 0.3995895243618068 and parameters: {'n_estimators': 130, 'max_depth': 16, 'min_samples_split': 0.22062606000433732, 'min_samples_leaf': 0.1225790328563128, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:34,809] Trial 97 finished with value: -0.021161345504918144 and parameters: {'n_estimators': 140, 'max_depth': 12, 'min_samples_split': 0.12405061352062072, 'min_samples_leaf': 0.41774981516162724, 'max_features': 'sqrt'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "\n",
            "[I 2024-01-28 01:31:35,499] Trial 98 finished with value: 0.37950973385010744 and parameters: {'n_estimators': 146, 'max_depth': 25, 'min_samples_split': 0.3092090438911311, 'min_samples_leaf': 0.13386669391273814, 'max_features': 'auto'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:35,618] Trial 99 finished with value: 0.37758430282129485 and parameters: {'n_estimators': 19, 'max_depth': 15, 'min_samples_split': 0.26053616417079384, 'min_samples_leaf': 0.11608818740628259, 'max_features': 'log2'}. Best is trial 36 with value: 0.4148177112674587.\n",
            "[I 2024-01-28 01:31:35,619] Finished hyperparameter search!\n",
            "[I 2024-01-28 01:31:35,623] Refitting the estimator using 353 samples...\n",
            "[I 2024-01-28 01:31:35,709] Finished refitting! (elapsed time: 0.084 sec.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 3053.615\n",
            "Best estimator: RandomForestRegressor(max_depth=17, max_features='sqrt',\n",
            "                      min_samples_leaf=0.10022239302145346,\n",
            "                      min_samples_split=0.20650593234907547, n_estimators=52,\n",
            "                      random_state=42)\n",
            "Number of finished trials: 100\n",
            "Best trial:\n",
            "  Value: 0.4148177112674587\n",
            "  Params: {'n_estimators': 52, 'max_depth': 17, 'min_samples_split': 0.20650593234907547, 'min_samples_leaf': 0.10022239302145346, 'max_features': 'sqrt'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b3e05695-090e-492c-bfb3-869b52583e41\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b3e05695-090e-492c-bfb3-869b52583e41\")) {                    Plotly.newPlot(                        \"b3e05695-090e-492c-bfb3-869b52583e41\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.3327181569191832,0.3362061919067875,-0.021966568118627183,0.26988966568828426,0.10515591582898043,-0.02168248842203953,0.19819725160063537,-0.021488741264716005,-0.021996752566249,-0.02122230007090331,-0.021688132864674747,0.3609366992250836,0.3360183966675572,-0.021784091680791946,0.40579313353557867,0.40720469091781436,0.3815682941655329,-0.021500452040449963,0.4018654586571666,0.32475969161033363,0.1220168533237398,0.4050082290199338,0.3544893181545586,0.38423317894632025,0.33209525796518485,0.40647327164828884,0.38736314717541953,0.3634241446484581,-0.021324005357352387,0.3085331002821868,0.3303257778660797,0.40715253365435977,0.4077621494575155,0.3904725895759203,0.36342103356977695,0.39095743715158204,0.4148177112674587,0.3095480861737048,0.37053958427871336,0.28814214281627304,-0.02142301156948682,0.41296630186159256,0.39240070799317683,0.39041709983217215,0.37489163949793863,0.3507392791499237,0.38347611022127265,0.037651027370353196,0.34829916993222043,0.36088902289129066,-0.02154438604187788,0.4050637216722979,0.4064724733763531,0.3858370645167861,0.4069724701959802,0.3882532295238659,0.24864601950574713,0.3889689154896369,0.3962916896268232,0.33200093413484977,0.41207541191043323,0.4142813353043173,0.40393024384382664,0.3866607762970357,0.3960264164024605,0.3873937787323957,0.3845796548063536,0.39818213364210225,-0.021757891373665128,-0.02199529055506762,0.3762784687690626,0.4082671611919115,0.3929281835894935,0.4010878672894241,0.407605657539742,0.37493167801409816,-0.02173015176052943,0.39809154940215025,0.38930266349173764,0.3636664308684366,0.30280250964403993,0.4017976295580084,0.38772172611202516,0.40804878124768357,0.39931498206157096,0.40430868725317115,0.3821458611463951,-0.021184414004724594,0.40748463263852946,0.39120377659337974,0.3780993048344225,0.40762229061235483,0.4011192641826753,0.40625875963934344,0.40596528157137407,0.31372540598558035,0.3995895243618068,-0.021161345504918144,0.37950973385010744,0.37758430282129485],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.3327181569191832,0.3362061919067875,0.3362061919067875,0.3362061919067875,0.3362061919067875,0.3362061919067875,0.3362061919067875,0.3362061919067875,0.3362061919067875,0.3362061919067875,0.3362061919067875,0.3609366992250836,0.3609366992250836,0.3609366992250836,0.40579313353557867,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.40720469091781436,0.4077621494575155,0.4077621494575155,0.4077621494575155,0.4077621494575155,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587,0.4148177112674587],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b3e05695-090e-492c-bfb3-869b52583e41');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    このコードでは、diabetes データセットを用いて、RandomForestRegressor モデルのハイパーパラメータチューニングを行います。\n",
        "    OptunaSearchCVを使用することで、簡単かつ効果的にハイパーパラメータの最適化が行えます。最後に、Optunaのビジュアライゼーション機能を利用して、探索の過程を視覚的に確認することができます。"
      ],
      "metadata": {
        "id": "pAHecXgFloBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## まとめ\n",
        "    今回は、OptunaSearchCVを使ったscikit-learnモデルのハイパーパラメータ最適化について学びました。\n",
        "\n",
        "    ・OptunaSearchCVの基本的な使い方とその利点。\n",
        "    ・ハイパーパラメータの探索空間の定義方法。\n",
        "    ・OptunaSearchCVでのプルーニングや交差検証との連携方法。\n",
        "    ・実際のデータセットを用いたモデルの最適化の実践例。\n",
        "\n",
        "    OptunaSearchCVは、Optunaの強力なハイパーパラメータチューニングの機能をscikit-learnのモデルに簡単に適用するためのツールです。\n",
        "    これにより、モデルの性能を向上させるためのハイパーパラメータを効率的に探索することができます。"
      ],
      "metadata": {
        "id": "5pONnY57sOqj"
      }
    }
  ]
}